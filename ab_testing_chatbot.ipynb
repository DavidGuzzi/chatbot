{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot para An√°lisis de A/B Testing\n",
    "\n",
    "Este notebook implementa un chatbot que puede leer y analizar datos de experimentos A/B testing desde archivos CSV/Excel y responder preguntas sobre los resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuraci√≥n del Entorno\n",
    "\n",
    "### Dependencias Necesarias\n",
    "```bash\n",
    "pip install pandas numpy scipy openai python-dotenv openpyxl\n",
    "```\n",
    "\n",
    "### Variables de Entorno\n",
    "Crea un archivo `.env` en el mismo directorio con:\n",
    "```\n",
    "OPENAI_API_KEY=tu_api_key_aqui\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cliente OpenAI inicializado correctamente\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# Cargar variables de entorno\n",
    "load_dotenv()\n",
    "\n",
    "# Verificar que la API key est√© configurada\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    print(\"‚ùå Error: OPENAI_API_KEY no encontrada en el archivo .env\")\n",
    "    print(\"üí° Soluci√≥n: Crea un archivo .env con tu API key:\")\n",
    "    print(\"   OPENAI_API_KEY=tu_api_key_aqui\")\n",
    "    client = None\n",
    "else:\n",
    "    try:\n",
    "        client = OpenAI(api_key=api_key)\n",
    "        print(\"‚úÖ Cliente OpenAI inicializado correctamente\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error al inicializar OpenAI: {e}\")\n",
    "        client = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Clase Principal del Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ABTestingChatbot:\n",
    "    def __init__(self):\n",
    "        self.detailed_data = None\n",
    "        self.analysis_cache = {}\n",
    "        \n",
    "        # Inicializar cliente OpenAI\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "        if api_key:\n",
    "            self.client = OpenAI(api_key=api_key)\n",
    "        else:\n",
    "            self.client = None\n",
    "            print(\"‚ö†Ô∏è Warning: No se pudo inicializar OpenAI. Configura OPENAI_API_KEY en .env\")\n",
    "        \n",
    "    def load_data(self, detailed_file: str):\n",
    "        \"\"\"\n",
    "        Carga solo los datos detallados del experimento\n",
    "        \"\"\"\n",
    "        if detailed_file.endswith('.csv'):\n",
    "            self.detailed_data = pd.read_csv(detailed_file)\n",
    "        elif detailed_file.endswith(('.xlsx', '.xls')):\n",
    "            self.detailed_data = pd.read_excel(detailed_file)\n",
    "        \n",
    "        print(f\"‚úÖ Datos detallados cargados:\")\n",
    "        print(f\"   - {len(self.detailed_data)} filas\")\n",
    "        print(f\"   - Experimentos: {', '.join(self.detailed_data['experimento'].unique())}\")\n",
    "    \n",
    "    def generate_context(self, question: str) -> str:\n",
    "        \"\"\"\n",
    "        Genera contexto relevante usando solo datos detallados\n",
    "        \"\"\"\n",
    "        if self.detailed_data is None:\n",
    "            return \"No hay datos cargados\"\n",
    "        \n",
    "        context_parts = []\n",
    "        \n",
    "        # Informaci√≥n b√°sica de los datos\n",
    "        context_parts.append(\"DATOS DETALLADOS DEL EXPERIMENTO:\")\n",
    "        context_parts.append(f\"Total de filas: {len(self.detailed_data)}\")\n",
    "        context_parts.append(f\"Experimentos: {', '.join(self.detailed_data['experimento'].unique())}\")\n",
    "        context_parts.append(f\"Columnas: {', '.join(self.detailed_data.columns)}\")\n",
    "        \n",
    "        # Incluir todos los datos detallados para que el LLM pueda hacer c√°lculos\n",
    "        context_parts.append(\"\\nDATOS COMPLETOS:\")\n",
    "        context_parts.append(self.detailed_data.to_string(index=False))\n",
    "        \n",
    "        return \"\\n\".join(context_parts)\n",
    "    \n",
    "    def chat(self, question: str) -> str:\n",
    "        \"\"\"\n",
    "        Procesa una pregunta y devuelve respuesta del chatbot\n",
    "        \"\"\"\n",
    "        if self.detailed_data is None:\n",
    "            return \"‚ùå Primero debes cargar los datos usando load_data()\"\n",
    "        \n",
    "        if self.client is None:\n",
    "            return \"‚ùå Cliente OpenAI no inicializado. Verifica tu OPENAI_API_KEY en el archivo .env\"\n",
    "        \n",
    "        # Generar contexto\n",
    "        context = self.generate_context(question)\n",
    "        \n",
    "        # Preparar prompt\n",
    "        system_prompt = \"\"\"\n",
    "        Eres un analista experto en A/B testing. Tu trabajo es analizar datos detallados de experimentos y responder preguntas calculando m√©tricas desde los datos granulares.\n",
    "        \n",
    "        IMPORTANTE:\n",
    "        - Debes hacer todos los c√°lculos bas√°ndote en los datos detallados proporcionados\n",
    "        - Para totales: suma todas las filas relevantes\n",
    "        - Para promedios: calcula desde los datos individuales\n",
    "        - Para comparaciones: agrupa y compara los datos seg√∫n la pregunta\n",
    "        - Muestra tus c√°lculos cuando sea relevante\n",
    "\n",
    "        NUNCA hagas sumas manuales. En su lugar:\n",
    "        1. Identifica qu√© experimento necesitas analizar\n",
    "        2. Filtra solo esas filas\n",
    "        3. Describe el proceso: \"Sumando usuarios de X filas del experimento Y\"\n",
    "        4. Da el resultado final\n",
    "        \n",
    "        Caracter√≠sticas de tus respuestas:\n",
    "        - Basadas en c√°lculos precisos de los datos detallados\n",
    "        - Incluyen n√∫meros espec√≠ficos y c√≥mo los calculaste\n",
    "        - Identifican patrones en los datos granulares\n",
    "        - Son claras y muestran el razonamiento\n",
    "        \n",
    "        Si necesitas hacer alg√∫n c√°lculo complejo, explica paso a paso c√≥mo lo obtuviste.\n",
    "        \"\"\"\n",
    "        \n",
    "        user_prompt = f\"\"\"\n",
    "        PREGUNTA: {question}\n",
    "        \n",
    "        CONTEXTO DE DATOS:\n",
    "        {context}\n",
    "        \n",
    "        Responde la pregunta calculando desde los datos detallados proporcionados. Muestra tu proceso de c√°lculo cuando sea relevante.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"GPT-4.5\",\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": user_prompt}\n",
    "                ],\n",
    "                max_tokens=1000,\n",
    "                temperature=0.1\n",
    "            )\n",
    "            return response.choices[0].message.content\n",
    "        except Exception as e:\n",
    "            return f\"‚ùå Error al consultar OpenAI: {str(e)}\"\n",
    "    \n",
    "    def show_data_preview(self):\n",
    "        \"\"\"\n",
    "        Muestra vista previa de los datos cargados\n",
    "        \"\"\"\n",
    "        if self.detailed_data is not None:\n",
    "            print(\"üìã DATOS DETALLADOS:\")\n",
    "            print(self.detailed_data.head(10))\n",
    "            print(f\"\\nShape: {self.detailed_data.shape}\")\n",
    "            print(f\"Columnas: {list(self.detailed_data.columns)}\")\n",
    "            \n",
    "            print(f\"\\nüìä Resumen por experimento:\")\n",
    "            for exp in self.detailed_data['experimento'].unique():\n",
    "                exp_data = self.detailed_data[self.detailed_data['experimento'] == exp]\n",
    "                print(f\"   {exp}: {len(exp_data)} tiendas, {exp_data['usuarios'].sum()} usuarios\")\n",
    "        else:\n",
    "            print(\"‚ùå No hay datos cargados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ejemplo de Uso\n",
    "\n",
    "### Crear datos de ejemplo para pruebas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Archivo de datos detallados creado:\n",
      "   - tiendas_detalle.csv\n",
      "\n",
      "üìä Datos generados:\n",
      "   - Total filas: 200\n",
      "   - Experimentos: ['Control' 'Experimento_A' 'Experimento_B' 'Experimento_C']\n",
      "   - Tiendas por experimento: 50\n",
      "\n",
      "üìà Estad√≠sticas por experimento:\n",
      "   Control: 11196 usuarios, 986 conversiones\n",
      "   Experimento_A: 11405 usuarios, 1073 conversiones\n",
      "   Experimento_B: 11900 usuarios, 1202 conversiones\n",
      "   Experimento_C: 11199 usuarios, 1304 conversiones\n"
     ]
    }
   ],
   "source": [
    "# Crear datos de ejemplo\n",
    "np.random.seed(42)\n",
    "\n",
    "# Solo crear datos detallados por tienda (sin resumen)\n",
    "tiendas_detalle = []\n",
    "experimentos = ['Control', 'Experimento_A', 'Experimento_B', 'Experimento_C']\n",
    "base_conversion_rates = [8.5, 9.4, 10.2, 11.9]\n",
    "\n",
    "for exp, base_conversion in zip(experimentos, base_conversion_rates):\n",
    "    for i in range(50):  # 50 tiendas por experimento\n",
    "        tiendas_detalle.append({\n",
    "            'experimento': exp,\n",
    "            'tienda_id': f'T_{exp}_{i+1:03d}',\n",
    "            'region': np.random.choice(['Norte', 'Sur', 'Este', 'Oeste']),\n",
    "            'tipo_tienda': np.random.choice(['Mall', 'Street', 'Outlet']),\n",
    "            'usuarios': np.random.randint(150, 300),\n",
    "            'conversiones': None,\n",
    "            'revenue': None,\n",
    "            'conversion_rate': np.random.normal(base_conversion, 2.5)\n",
    "        })\n",
    "\n",
    "tiendas_df = pd.DataFrame(tiendas_detalle)\n",
    "tiendas_df['conversiones'] = (tiendas_df['usuarios'] * tiendas_df['conversion_rate'] / 100).round().astype(int)\n",
    "tiendas_df['revenue'] = tiendas_df['conversiones'] * np.random.uniform(15, 25, len(tiendas_df))\n",
    "tiendas_df['conversion_rate'] = tiendas_df['conversion_rate'].round(2)\n",
    "\n",
    "# Guardar solo el archivo de datos detallados\n",
    "tiendas_df.to_csv('tiendas_detalle.csv', index=False)\n",
    "\n",
    "print(\"‚úÖ Archivo de datos detallados creado:\")\n",
    "print(\"   - tiendas_detalle.csv\")\n",
    "print(f\"\\nüìä Datos generados:\")\n",
    "print(f\"   - Total filas: {len(tiendas_df)}\")\n",
    "print(f\"   - Experimentos: {tiendas_df['experimento'].unique()}\")\n",
    "print(f\"   - Tiendas por experimento: {len(tiendas_df) // len(experimentos)}\")\n",
    "\n",
    "# Mostrar estad√≠sticas por experimento\n",
    "print(f\"\\nüìà Estad√≠sticas por experimento:\")\n",
    "for exp in experimentos:\n",
    "    exp_data = tiendas_df[tiendas_df['experimento'] == exp]\n",
    "    print(f\"   {exp}: {exp_data['usuarios'].sum()} usuarios, {exp_data['conversiones'].sum()} conversiones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializar el Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Datos detallados cargados:\n",
      "   - 200 filas\n",
      "   - Experimentos: Control, Experimento_A, Experimento_B, Experimento_C\n",
      "üìã DATOS DETALLADOS:\n",
      "  experimento      tienda_id region tipo_tienda  usuarios  conversiones  \\\n",
      "0     Control  T_Control_001   Este        Mall       164            17   \n",
      "1     Control  T_Control_002   Este      Street       224            28   \n",
      "2     Control  T_Control_003   Este        Mall       249            24   \n",
      "3     Control  T_Control_004  Norte      Street       237            15   \n",
      "4     Control  T_Control_005  Oeste      Street       187            23   \n",
      "5     Control  T_Control_006  Norte        Mall       198            24   \n",
      "6     Control  T_Control_007   Este      Outlet       164            20   \n",
      "7     Control  T_Control_008   Este      Outlet       213            17   \n",
      "8     Control  T_Control_009  Norte      Outlet       200            14   \n",
      "9     Control  T_Control_010    Sur        Mall       209            28   \n",
      "\n",
      "      revenue  conversion_rate  \n",
      "0  319.391346            10.12  \n",
      "1  514.485113            12.31  \n",
      "2  575.915375             9.48  \n",
      "3  316.133283             6.18  \n",
      "4  401.201226            12.16  \n",
      "5  479.579447            12.35  \n",
      "6  366.069696            12.16  \n",
      "7  413.727610             7.94  \n",
      "8  211.054811             7.19  \n",
      "9  483.093183            13.28  \n",
      "\n",
      "Shape: (200, 8)\n",
      "Columnas: ['experimento', 'tienda_id', 'region', 'tipo_tienda', 'usuarios', 'conversiones', 'revenue', 'conversion_rate']\n",
      "\n",
      "üìä Resumen por experimento:\n",
      "   Control: 50 tiendas, 11196 usuarios\n",
      "   Experimento_A: 50 tiendas, 11405 usuarios\n",
      "   Experimento_B: 50 tiendas, 11900 usuarios\n",
      "   Experimento_C: 50 tiendas, 11199 usuarios\n"
     ]
    }
   ],
   "source": [
    "# Crear instancia del chatbot\n",
    "chatbot = ABTestingChatbot()\n",
    "\n",
    "# Cargar solo datos detallados\n",
    "chatbot.load_data('tiendas_detalle.csv')\n",
    "\n",
    "# Mostrar preview\n",
    "chatbot.show_data_preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ejemplos de Preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Pregunta: ¬øCu√°l fue el mejor experimento y por qu√©?\n",
      "üí¨ Respuesta: El mejor experimento fue Experimento_C. Este experimento tuvo un total de 1180 conversiones, generando un revenue total de 189,000 unidades monetarias. Adem√°s, tuvo la tasa de conversi√≥n m√°s alta de 11.9% y el revenue por usuario m√°s alto de 19.1 unidades monetarias. \n",
      "\n",
      "Comparado con el grupo de control, Experimento_C tuvo un ROI significativamente mayor de 52.8, lo que indica un rendimiento mucho mejor en t√©rminos de retorno de la inversi√≥n.\n",
      "\n",
      "Por lo tanto, bas√°ndonos en los datos proporcionados, Experimento_C fue el mejor en t√©rminos de m√©tricas clave y retorno de la inversi√≥n.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 1: ¬øCu√°l fue el mejor experimento?\n",
    "pregunta_1 = \"¬øCu√°l fue el mejor experimento y por qu√©?\"\n",
    "print(f\"ü§ñ Pregunta: {pregunta_1}\")\n",
    "print(f\"üí¨ Respuesta: {chatbot.chat(pregunta_1)}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Pregunta: ¬øCu√°les experimentos son estad√≠sticamente significativos y qu√© significa esto?\n",
      "üí¨ Respuesta: Bas√°ndome en los datos proporcionados, los experimentos estad√≠sticamente significativos son Experimento_A, Experimento_B y Experimento_C. Esto significa que los resultados obtenidos en estos experimentos no se deben al azar, sino que son resultado de las variaciones introducidas en comparaci√≥n con el grupo de control de manera significativa.\n",
      "\n",
      "- Experimento_A tiene un p-value de 0.0230, lo que indica que hay una diferencia significativa en comparaci√≥n con el grupo de control.\n",
      "- Experimento_B tiene un p-value de 0.0010, mostrando una diferencia a√∫n m√°s significativa.\n",
      "- Experimento_C es el m√°s significativo con un p-value de 0.0001, lo que sugiere una diferencia altamente significativa.\n",
      "\n",
      "Estos resultados indican que los Experimentos A, B y C han generado mejoras significativas en conversiones, ingresos totales, tasas de conversi√≥n, ingresos por usuario y retorno de inversi√≥n en comparaci√≥n con el grupo de control. Recomendar√≠a seguir explorando y potenciando los elementos que llevaron a estos resultados positivos para maximizar el impacto en la estrategia general.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 2: An√°lisis de significancia\n",
    "pregunta_2 = \"¬øCu√°les experimentos son estad√≠sticamente significativos y qu√© significa esto?\"\n",
    "print(f\"ü§ñ Pregunta: {pregunta_2}\")\n",
    "print(f\"üí¨ Respuesta: {chatbot.chat(pregunta_2)}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Pregunta: ¬øHay diferencias en el performance por regi√≥n o tipo de tienda?\n",
      "üí¨ Respuesta: Para analizar si hay diferencias en el performance por regi√≥n o tipo de tienda, podemos revisar los datos detallados de usuarios, conversiones, revenue y conversion rate por regi√≥n y tipo de tienda en cada experimento.\n",
      "\n",
      "### Por Regi√≥n:\n",
      "- **Este:** Experimento_C tiene el mejor desempe√±o en esta regi√≥n, con una tasa de conversi√≥n de 11.9% y un revenue por usuario de 19.1.\n",
      "- **Norte:** Experimento_C tambi√©n destaca en esta regi√≥n, con una tasa de conversi√≥n de 11.9% y un revenue por usuario de 19.1.\n",
      "- **Oeste:** No hay datos detallados para el Oeste, por lo que no podemos comparar el desempe√±o en esta regi√≥n.\n",
      "- **Sur:** No hay datos detallados para el Sur, por lo que no podemos comparar el desempe√±o en esta regi√≥n.\n",
      "\n",
      "### Por Tipo de Tienda:\n",
      "- **Mall:** Experimento_C muestra un buen desempe√±o en este tipo de tienda, con una tasa de conversi√≥n de 11.9% y un revenue por usuario de 19.1.\n",
      "- **Street:** Experimento_B tiene un buen desempe√±o en tiendas de calle, con una tasa de conversi√≥n de 10.2% y un revenue por usuario de 16.4.\n",
      "- **Outlet:** No hay datos detallados para tiendas Outlet, por lo que no podemos comparar el desempe√±o en este tipo de tienda.\n",
      "\n",
      "En resumen, bas√°ndonos en los datos disponibles, Experimento_C parece ser el m√°s exitoso en t√©rminos de conversiones y revenue por usuario en las regiones Este y Norte, as√≠ como en tiendas de tipo Mall. Para obtener conclusiones m√°s s√≥lidas, ser√≠a √∫til contar con datos detallados de las regiones Oeste y Sur, as√≠ como de tiendas Outlet.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 3: An√°lisis por tienda/regi√≥n\n",
    "pregunta_3 = \"¬øHay diferencias en el performance por regi√≥n o tipo de tienda?\"\n",
    "print(f\"ü§ñ Pregunta: {pregunta_3}\")\n",
    "print(f\"üí¨ Respuesta: {chatbot.chat(pregunta_3)}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Pregunta: ¬øQu√© experimento recomendar√≠as implementar y por qu√©?\n",
      "üí¨ Respuesta: Bas√°ndome en los datos proporcionados, recomendar√≠a implementar un nuevo experimento que combine las estrategias m√°s exitosas de los Experimentos B y C. \n",
      "\n",
      "El Experimento B mostr√≥ un aumento significativo en conversiones, revenue total, conversion rate, revenue por usuario y ROI en comparaci√≥n con el Control. Por otro lado, el Experimento C tuvo resultados a√∫n m√°s impresionantes en todas estas m√©tricas, superando al Experimento B.\n",
      "\n",
      "Al combinar elementos clave de ambos experimentos, como posiblemente la estrategia de marketing utilizada en el Experimento B con la optimizaci√≥n de la experiencia de usuario del Experimento C, es probable que se logren resultados a√∫n m√°s impactantes en t√©rminos de conversiones, ingresos y retorno de inversi√≥n.\n",
      "\n",
      "Ser√≠a importante dise√±ar este nuevo experimento de manera cuidadosa, manteniendo un enfoque claro en las m√©tricas clave que han demostrado ser significativas en experimentos anteriores, y asegur√°ndose de realizar pruebas adecuadas para validar la efectividad de las estrategias combinadas.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pregunta 4: Recomendaciones\n",
    "pregunta_4 = \"¬øQu√© experimento recomendar√≠as implementar y por qu√©?\"\n",
    "print(f\"ü§ñ Pregunta: {pregunta_4}\")\n",
    "print(f\"üí¨ Respuesta: {chatbot.chat(pregunta_4)}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interfaz Interactiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Chatbot de A/B Testing iniciado!\n",
      "üí° Escribe 'salir' para terminar\n",
      "\n",
      "\n",
      "üí¨ Respuesta: ‚ùå Error al consultar OpenAI: Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "üëã ¬°Hasta luego!\n"
     ]
    }
   ],
   "source": [
    "def chat_interactivo():\n",
    "    \"\"\"\n",
    "    Funci√≥n para chat interactivo\n",
    "    \"\"\"\n",
    "    print(\"ü§ñ Chatbot de A/B Testing iniciado!\")\n",
    "    print(\"üí° Escribe 'salir' para terminar\\n\")\n",
    "    \n",
    "    while True:\n",
    "        pregunta = input(\"ü§î Tu pregunta: \")\n",
    "        \n",
    "        if pregunta.lower() in ['salir', 'exit', 'quit']:\n",
    "            print(\"üëã ¬°Hasta luego!\")\n",
    "            break\n",
    "        \n",
    "        if pregunta.strip() == \"\":\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nüí¨ Respuesta: {chatbot.chat(pregunta)}\")\n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Descomentar la siguiente l√≠nea para usar el chat interactivo\n",
    "chat_interactivo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pr√≥ximos Pasos\n",
    "\n",
    "### Mejoras Posibles:\n",
    "1. **An√°lisis m√°s sofisticados**: Intervalos de confianza, power analysis\n",
    "2. **Visualizaciones**: Gr√°ficos autom√°ticos con matplotlib/plotly\n",
    "3. **Memoria conversacional**: Recordar preguntas anteriores\n",
    "4. **Validaci√≥n de datos**: Detecci√≥n autom√°tica de anomal√≠as\n",
    "5. **Export de insights**: Generar reportes autom√°ticos\n",
    "\n",
    "### Para Usar con Tus Datos:\n",
    "1. Reemplaza `experimentos_resumen.csv` y `tiendas_detalle.csv` con tus archivos\n",
    "2. Ajusta los nombres de columnas en la clase si es necesario\n",
    "3. Configura tu `OPENAI_API_KEY` en el archivo `.env`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
